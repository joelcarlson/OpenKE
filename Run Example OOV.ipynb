{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./benchmarks/FB15K/\"\n",
    "test_data_path = \"./benchmarks/FB15K_OOV/\"\n",
    "\n",
    "train_file_path = \"./res/model.vec.tf\"\n",
    "train_embedding_path = \"./res/embedding.vec.json\"\n",
    "\n",
    "test_file_path = \"./res/model_new.vec.tf\"\n",
    "test_embedding_path = \"./res/embedding_new.vec.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TransE To Create initial embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method:\n",
    "\n",
    "Run the normal transe example (example_train_transe.py)\n",
    "Write the embeddings as a file that can be read\n",
    "use embeddings to initialize embedding layer in TransE_freeze.py\n",
    "\n",
    "Append random embeddings for new entities and relations\n",
    "set config freeze_train_embeddings = true\n",
    "figure out how to update only the embeddings for a certain set of indices\n",
    "figure out how to make sure that we only see examples using new items to speed convergence\n",
    "compare new+old embeddings\n",
    "\"\"\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "con = config.Config()\n",
    "#True: Input test files from the same folder.\n",
    "con.set_in_path(train_data_path)\n",
    "con.set_test_link_prediction(True)\n",
    "con.set_test_triple_classification(True)\n",
    "con.set_work_threads(8)\n",
    "con.set_train_times(10)\n",
    "con.set_nbatches(20)\n",
    "con.set_alpha(0.001)\n",
    "con.set_margin(1.0)\n",
    "con.set_bern(0)\n",
    "con.set_dimension(100)\n",
    "con.set_ent_neg_rate(1)\n",
    "con.set_rel_neg_rate(0)\n",
    "con.set_opt_method(\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models will be exported via tf.Saver() automatically.\n",
    "con.set_export_files(train_file_path, 0)\n",
    "#Model parameters will be exported to json files automatically.\n",
    "con.set_out_files(train_embedding_path)\n",
    "#Initialize experimental settings.\n",
    "con.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set the knowledge embedding model\n",
    "con.set_model(models.TransE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model.\n",
    "con.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TransE Freeze using Embeddings produced in above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "#Input training files from benchmarks/FB15K/ folder.\n",
    "con = config.Config()\n",
    "#True: Input test files from the same folder.\n",
    "con.set_in_path(test_data_path)\n",
    "con.set_test_link_prediction(False)\n",
    "con.set_test_triple_classification(False)\n",
    "con.set_work_threads(8)\n",
    "con.set_train_times(10)\n",
    "con.set_nbatches(6) # Total obs = 18 . Need ~3 per batch, so batch size = total / n_batches \n",
    "con.set_alpha(0.001)\n",
    "con.set_margin(1.0)\n",
    "con.set_bern(0)\n",
    "con.set_dimension(100)\n",
    "con.set_ent_neg_rate(1)\n",
    "con.set_rel_neg_rate(0)\n",
    "con.set_opt_method(\"SGD\")\n",
    "\n",
    "\n",
    "con.set_freeze_train_embeddings(True)\n",
    "con.set_embedding_initializer_path(train_embedding_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Imported train\n",
      "WARNING:root:Got train total: 19\n",
      "WARNING:root:Got test total: 0\n",
      "WARNING:root:Got val total: 0\n",
      "WARNING:root:Set batch size: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New entities found:\n",
      "-- Total Entities in embedding file: 14951\n",
      "-- Total Entities in data: 14970 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Initialized embeddings from: ./res/embedding.vec.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New relationships found:\n",
      "-- Total Relationships in embedding file: 1345\n",
      "-- Total Relationships in data: 1354 \n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:root:Initialized embddings in transE\n",
      "WARNING:root:made it to fake pos r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joelcarl/WorkDocs/Scratch/PBG/OpenKE_round2/OpenKE/models/TransE_freeze.py:119: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joelcarl/WorkDocs/Scratch/PBG/OpenKE_round2/OpenKE/models/TransE_freeze.py:119: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "#Models will be exported via tf.Saver() automatically.\n",
    "con.set_export_files(test_file_path, 0)\n",
    "#Model parameters will be exported to json files automatically.\n",
    "con.set_out_files(test_embedding_path)\n",
    "#Initialize experimental settings.\n",
    "con.init()\n",
    "#Set the knowledge embedding model\n",
    "con.set_model(models.TransE_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 3.031768798828125, time: 0.0\n",
      "Epoch: 1, loss: 2.1548867225646973, time: 1.1920928955078125e-06\n",
      "Epoch: 2, loss: 3.203535556793213, time: 0.0\n",
      "Epoch: 3, loss: 2.2079691886901855, time: 0.0\n",
      "Epoch: 4, loss: 1.8855860233306885, time: 0.0\n",
      "Epoch: 5, loss: 2.1341300010681152, time: 9.5367431640625e-07\n",
      "Epoch: 6, loss: 0.8497586250305176, time: 0.0\n",
      "Epoch: 7, loss: 2.463907241821289, time: 0.0\n",
      "Epoch: 8, loss: 2.1021907329559326, time: 0.0\n",
      "Epoch: 9, loss: 2.0507194995880127, time: 9.5367431640625e-07\n"
     ]
    }
   ],
   "source": [
    "#Train the model.\n",
    "con.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare new and old embeddings\n",
    "\n",
    "- Any entity or relationship that was created in the training data should be the same\n",
    "- Any entity or relationship that was created in the training data, but involved in the test data should still be the same\n",
    "- Any entity or relationship that was not created in training should be different\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./res/embedding.vec.json\", \"r\") as f: \n",
    "    old_embeddings = json.loads(f.read())\n",
    "    old_ent_embeddings = old_embeddings[\"ent_embeddings\"]\n",
    "    old_rel_embeddings = old_embeddings[\"rel_embeddings\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./res/embedding_new.vec.json\", \"r\") as f: \n",
    "    new_embeddings = json.loads(f.read())\n",
    "    new_ent_embeddings = new_embeddings[\"ent_embeddings\"]\n",
    "    new_rel_embeddings = new_embeddings[\"rel_embeddings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities that should be the same are all entities below (and including) 14950, but in train2id\n",
    "# e.g. 1234, 1018, 4169\n",
    "print(old_ent_embeddings[1233] == new_ent_embeddings[1233])\n",
    "print(old_ent_embeddings[1234] == new_ent_embeddings[1234])\n",
    "print(old_ent_embeddings[1235] == new_ent_embeddings[1235])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities that are new should have embeddings in the new data, but not in the old\n",
    "try:\n",
    "    print(old_ent_embeddings[14951])\n",
    "except IndexError:\n",
    "    print(\"No embedding for entity 14951 in train embeddings\")\n",
    "    \n",
    "print(\"Embedding for entity 14951 in new embeddings:\")    \n",
    "print(new_ent_embeddings[14951][0:10])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationships that should be the same are all entities below (and including) 1344, but in train2id\n",
    "# e.g. 58, 135, 38\n",
    "print(old_rel_embeddings[57] == new_rel_embeddings[57])\n",
    "print(old_rel_embeddings[58] == new_rel_embeddings[58])\n",
    "print(old_rel_embeddings[59] == new_rel_embeddings[59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationships that are new should have embeddings in the new data, but not in the old\n",
    "try:\n",
    "    print(old_rel_embeddings[1345])\n",
    "except IndexError:\n",
    "    print(\"No relationship embedding for 1345 in train embeddings\")\n",
    "    \n",
    "print(\"Embedding for relationship 1345 in new embeddings:\")    \n",
    "print(new_rel_embeddings[1345][0:10])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lengths should be as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(old_ent_embeddings))\n",
    "print(len(new_ent_embeddings))\n",
    "print(len(old_rel_embeddings))\n",
    "print(len(new_rel_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rel_embeddings[1353][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PBG] *",
   "language": "python",
   "name": "conda-env-PBG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
