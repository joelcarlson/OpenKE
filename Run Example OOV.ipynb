{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./benchmarks/FB15K/\"\n",
    "test_data_path = \"./benchmarks/FB15K_OOV/\"\n",
    "\n",
    "train_file_path = \"./res/model.vec.tf\"\n",
    "train_embedding_path = \"./res/embedding.vec.json\"\n",
    "\n",
    "test_file_path = \"./res/model_new.vec.tf\"\n",
    "test_embedding_path = \"./res/embedding_new.vec.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TransE To Create initial embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method:\n",
    "\n",
    "Run the normal transe example (example_train_transe.py)\n",
    "Write the embeddings as a file that can be read\n",
    "use embeddings to initialize embedding layer in TransE_freeze.py\n",
    "\n",
    "Append random embeddings for new entities and relations\n",
    "set config freeze_train_embeddings = true\n",
    "figure out how to update only the embeddings for a certain set of indices\n",
    "figure out how to make sure that we only see examples using new items to speed convergence\n",
    "compare new+old embeddings\n",
    "\"\"\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "con = config.Config()\n",
    "#True: Input test files from the same folder.\n",
    "con.set_in_path(train_data_path)\n",
    "con.set_test_link_prediction(True)\n",
    "con.set_test_triple_classification(True)\n",
    "con.set_work_threads(8)\n",
    "con.set_train_times(10)\n",
    "con.set_nbatches(20)\n",
    "con.set_alpha(0.001)\n",
    "con.set_margin(1.0)\n",
    "con.set_bern(0)\n",
    "con.set_dimension(100)\n",
    "con.set_ent_neg_rate(1)\n",
    "con.set_rel_neg_rate(0)\n",
    "con.set_opt_method(\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models will be exported via tf.Saver() automatically.\n",
    "con.set_export_files(train_file_path, 0)\n",
    "#Model parameters will be exported to json files automatically.\n",
    "con.set_out_files(train_embedding_path)\n",
    "#Initialize experimental settings.\n",
    "con.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set the knowledge embedding model\n",
    "con.set_model(models.TransE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model.\n",
    "con.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TransE Freeze using Embeddings produced in above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "#Input training files from benchmarks/FB15K/ folder.\n",
    "con = config.Config()\n",
    "#True: Input test files from the same folder.\n",
    "con.set_in_path(test_data_path)\n",
    "con.set_test_link_prediction(False)\n",
    "con.set_test_triple_classification(False)\n",
    "con.set_work_threads(8)\n",
    "con.set_train_times(10)\n",
    "con.set_nbatches(2) # Total obs = 18 . Need ~3 per batch, so batch size = total / n_batches \n",
    "con.set_alpha(0.001)\n",
    "con.set_margin(1.0)\n",
    "con.set_bern(0)\n",
    "con.set_dimension(100)\n",
    "con.set_ent_neg_rate(1)\n",
    "con.set_rel_neg_rate(0)\n",
    "con.set_opt_method(\"SGD\")\n",
    "\n",
    "\n",
    "con.set_freeze_train_embeddings(True)\n",
    "con.set_embedding_initializer_path(train_embedding_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:imported train\n",
      "WARNING:root:got train total\n",
      "WARNING:root:got test total\n",
      "WARNING:root:got val total\n",
      "WARNING:root:set batch size\n",
      "WARNING:root:Assigned batches\n",
      "WARNING:root:Assigned np array interfaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many entities!\n",
      "Total Entities in data: 14968 \n",
      "Total Entities in Embedding file: 14951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:initialized embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many relationships!\n",
      "Total Relationships in data: 1352 \n",
      "Total Relationships in Embedding file: 1345\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:root:Initialized embddings in transE\n",
      "WARNING:root:made it to fake pos r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos_h\n",
      "Tensor(\"model/input/transpose:0\", shape=(9, 1), dtype=int64)\n",
      "Tensor(\"model/loss/embedding_lookup/Identity:0\", shape=(9, 1, 100), dtype=float32)\n",
      "pos_t\n",
      "Tensor(\"model/input/transpose:0\", shape=(9, 1), dtype=int64)\n",
      "Tensor(\"model/loss/embedding_lookup_1/Identity:0\", shape=(9, 1, 100), dtype=float32)\n",
      "pos_r\n",
      "Tensor(\"model/input/transpose_2:0\", shape=(9, 1), dtype=int64)\n",
      "Tensor(\"model/loss/embedding_lookup_2/Identity:0\", shape=(9, 1, 100), dtype=float32)\n",
      "neg_h\n",
      "Tensor(\"model/input/transpose_3:0\", shape=(9, 1), dtype=int64)\n",
      "Tensor(\"model/loss/embedding_lookup_3/Identity:0\", shape=(9, 1, 100), dtype=float32)\n",
      "neg_t\n",
      "Tensor(\"model/input/transpose_3:0\", shape=(9, 1), dtype=int64)\n",
      "Tensor(\"model/loss/embedding_lookup_4/Identity:0\", shape=(9, 1, 100), dtype=float32)\n",
      "neg_r\n",
      "Tensor(\"model/input/transpose_5:0\", shape=(9, 1), dtype=int64)\n",
      "Tensor(\"model/loss/embedding_lookup_5/Identity:0\", shape=(9, 1, 100), dtype=float32)\n",
      "WARNING:tensorflow:From /Users/joelcarl/WorkDocs/Scratch/PBG/OpenKE_round2/OpenKE/models/TransE_freeze.py:119: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joelcarl/WorkDocs/Scratch/PBG/OpenKE_round2/OpenKE/models/TransE_freeze.py:119: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/PBG/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "#Models will be exported via tf.Saver() automatically.\n",
    "con.set_export_files(test_file_path, 0)\n",
    "#Model parameters will be exported to json files automatically.\n",
    "con.set_out_files(test_embedding_path)\n",
    "#Initialize experimental settings.\n",
    "con.init()\n",
    "#Set the knowledge embedding model\n",
    "con.set_model(models.TransE_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 9.79340934753418, time: 0.0\n",
      "Epoch: 1, loss: 7.868074178695679, time: 0.0\n",
      "Epoch: 2, loss: 8.77539348602295, time: 0.0\n",
      "Epoch: 3, loss: 8.584557294845581, time: 9.5367431640625e-07\n",
      "Epoch: 4, loss: 7.646888256072998, time: 1.1920928955078125e-06\n",
      "Epoch: 5, loss: 7.066133499145508, time: 0.0\n",
      "Epoch: 6, loss: 7.60280966758728, time: 0.0\n",
      "Epoch: 7, loss: 3.622953176498413, time: 0.0\n",
      "Epoch: 8, loss: 4.594324827194214, time: 9.5367431640625e-07\n",
      "Epoch: 9, loss: 8.525736570358276, time: 9.5367431640625e-07\n"
     ]
    }
   ],
   "source": [
    "#Train the model.\n",
    "con.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare new and old embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./res/embedding.vec.json\", \"r\") as f: \n",
    "    old_embeddings = json.loads(f.read())\n",
    "    old_ent_embeddings = old_embeddings[\"ent_embeddings\"]\n",
    "    old_rel_embeddings = old_embeddings[\"rel_embeddings\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./res/embedding_new.vec.json\", \"r\") as f: \n",
    "    new_embeddings = json.loads(f.read())\n",
    "    new_ent_embeddings = new_embeddings[\"ent_embeddings\"]\n",
    "    new_rel_embeddings = new_embeddings[\"rel_embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_ent_embeddings[1235][0:10] == new_ent_embeddings[1235][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ent_embeddings[1233][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does anything actually happen to the embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ent_embeddings[-1] == new_ent_embeddings[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be false\n",
    "old_rel_embeddings[-1] == new_rel_embeddings[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be TRUE\n",
    "old_rel_embeddings[-1] == new_rel_embeddings[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_rel_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old_rel_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.concatenate((25*np.ones([3,1], dtype=np.int),50*np.ones([3,1], dtype=np.int)), 0) > 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PBG] *",
   "language": "python",
   "name": "conda-env-PBG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
